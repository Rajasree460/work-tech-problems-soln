{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda8e5b-b61c-4ce3-83b7-293b4f291053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Paths to the data files\n",
    "train_file_path = '/content/optdigits.tra' test_file_path = '/content/optdigits.tes'\n",
    "\n",
    "\n",
    "\n",
    "# Load the training and testing data\n",
    "train_data = pd.read_csv(train_file_path, header=None) test_data = pd.read_csv(test_file_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data.iloc[:, :-1].values # All columns except the last one y_train = train_data.iloc[:, -1].values\t# The last column as labels\n",
    "\n",
    "X_test = test_data.iloc[:, :-1].values\t# All columns except the last one y_test = test_data.iloc[:, -1].values\t# The last column as labels\n",
    "\n",
    "\n",
    "# Dictionary to store model names and their accuracies model_accuracies = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ffeee-cc0e-47e5-80e5-28fc7a42bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the K-Nearest Neighbors (KNN) classifier knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set y_pred = knn.predict(X_test)\n",
    "model_accuracies['KNN'] = accuracy_score(y_test, y_pred) print(f'Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8b1c6-0214-4966-bf50-1e95e8f37994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over different values of k for i, k in enumerate(neighbors):\n",
    "# Setup a k-NN Classifier with k neighbors: knn knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the classifier to the training data knn.fit(X_train, y_train)\n",
    "\n",
    "#Compute accuracy on the training set train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "#Compute accuracy on the testing set test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Generate plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('k-NN: Varying Number of Neighbors') plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy') plt.plot(neighbors, train_accuracy, label = 'Training Accuracy') plt.legend()\n",
    "plt.xlabel('Number of Neighbors') plt.ylabel('Accuracy') plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee88dfc-031b-40eb-a23e-07acb669115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB() nb_model.fit(X_train, y_train) y_pred_nb = nb_model.predict(X_test)\n",
    "model_accuracies['Naive Bayes'] = accuracy_score(y_test, y_pred_nb) print(f'Accuracy: {accuracy_score(y_test, y_pred_nb) * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b654eb0-a5f7-425f-913d-39bd4328ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=0) dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "model_accuracies['Decision Tree'] = accuracy_score(y_test, y_pred_dt) print(f'Accuracy: {accuracy_score(y_test, y_pred_dt) * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013c1a5-5c45-46aa-ac27-b5856f79d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0) rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "model_accuracies['Random Forest'] = accuracy_score(y_test, y_pred_rf) print(f'Accuracy: {accuracy_score(y_test, y_pred_rf) * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001ef62-27b2-4e91-968d-27915d954216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the test accuracies plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_accuracies.keys(), model_accuracies.values(), color=['blue', 'yellow', 'green', 'red']) plt.xlabel('Model')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy of Different Models')\n",
    "plt.ylim(0, 1) # Scale the y-axis from 0 to 1 for percentage accuracy plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340a39b-1f8d-40d6-a098-5b6d2528067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of classifiers to evaluate classifiers = {\n",
    "\"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5), \"Naive Bayes\": GaussianNB(),\n",
    "\"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "\"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "}\n",
    "\n",
    "# Dictionary to store performance metrics for each classifier performance_data = []\n",
    "\n",
    "# Evaluate each classifier\n",
    "for name, model in classifiers.items(): # Train the model model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True) precision = report['weighted avg']['precision']\n",
    "recall = report['weighted avg']['recall'] f1_score = report['weighted avg']['f1-score']\n",
    "\n",
    "# Append the results to the performance data performance_data.append({\n",
    "\"Classifier\": name, \"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall,\n",
    "\"F1 Score\": f1_score\n",
    "})\n",
    "\n",
    "# Create a DataFrame from the performance data performance_df = pd.DataFrame(performance_data)\n",
    "\n",
    "# Display the performance table print(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213a0a8-859a-4e56-bb61-9bdb180295fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the F1 scores plt.figure(figsize=(10, 6))\n",
    "plt.bar(f1_scores.keys(), f1_scores.values(), color=['pink', 'yellow', 'orange', 'green']) plt.xlabel('Model')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Comparison of F1 Scores for Different Classifiers') plt.ylim(0, 1) # Scale y-axis from 0 to 1\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
