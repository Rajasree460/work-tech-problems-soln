{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf97e8-4ba2-4826-89da-a741c6154252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "# Importing the dataset\n",
    "\n",
    "df = pd.read_excel('real_estate_valuation.xlsx', index_col=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273b73c-1b90-4d54-93be-a6b08593536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing the dataset\n",
    "\n",
    "df.shape\n",
    "df.describe()\n",
    "df.info()\n",
    "\n",
    "#Finding missing values\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "#Extracting transaction year and dropping transaction date\n",
    "\n",
    "df['transaction year'] = df['X1 transaction date'].apply(lambda x: int(x))\n",
    "df = df.drop(columns = 'X1 transaction date')\n",
    "df.info()\n",
    "\n",
    "#Histogram plot to visualize distribution of data\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, j in enumerate(df.columns, 1):\n",
    "    plt.subplot(4, 2, i) \n",
    "    sns.histplot(df[j], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {j}')\n",
    "    plt.xlabel(j)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Boxplot for better visualization of outliers in features and their spread\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, j in enumerate(df.columns):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x=df[j])\n",
    "    plt.title(f'Boxplot for {j}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Logarithmic transformation of ‘distance to nearest MRT station’ to counteract skewness and handle outliers\n",
    "\n",
    "df['X3 distance to the nearest MRT station'] = np.log1p(df['X3 distance to the nearest MRT station'])\n",
    "df['X3 distance to the nearest MRT station'].hist(bins=50)\n",
    "sns.boxplot(x=df['X3 distance to the nearest MRT station'])\n",
    "\n",
    "#Forming a correlation matrix and generating a heatmap\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "#splitting data into 75-25% training and test set\n",
    "\n",
    "X = df.drop(columns = 'Y house price of unit area')\n",
    "Y = df['Y house price of unit area']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "#Normalization of the features using StrandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Using GridSearch to find the optimal parameters for linear regression\n",
    "\n",
    "linear_regression_params = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False]\n",
    "}\n",
    "\n",
    "linear_regression_grid = GridSearchCV(estimator=LinearRegression(), param_grid=linear_regression_params, \n",
    "                                      scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "linear_regression_grid.fit(X_train_scaled, Y_train)\n",
    "best_lr_model = linear_regression_grid.best_estimator_\n",
    "best_lr_params = linear_regression_grid.best_params_\n",
    "\n",
    "print(\"Best Linear Regression Parameters:\", best_lr_params)\n",
    "\n",
    "#Linear regression with optimal parameters\n",
    "\n",
    "lin_reg = LinearRegression() #default hyperparameter settings are found to be the best\n",
    "lin_reg.fit(X_train_scaled, Y_train)\n",
    "y_pred_linear = lin_reg.predict(X_test_scaled)\n",
    "\n",
    "#Evaluation of linear regression model\n",
    "\n",
    "linear_rmse = root_mean_squared_error(Y_test, y_pred_linear)\n",
    "linear_r2 = r2_score(Y_test, y_pred_linear)\n",
    "linear_mae = mean_absolute_error(Y_test, y_pred_linear)\n",
    "\n",
    "print(f'Root Mean Squared Error : {linear_rmse}\\nR2-score : {linear_r2}\\nMean Absolute Error : {linear_mae}')\n",
    "\n",
    "#Binarization of target value\n",
    "\n",
    "median_price = Y_train.median()\n",
    "y_train_binary = (Y_train >= median_price).astype(int)\n",
    "y_test_binary = (Y_test >= median_price).astype(int)\n",
    "\n",
    "#Using GridSearch to find optimal parameters for logistic regression model\n",
    "\n",
    "logistic_regression_params = {\n",
    "    'max_iter' : [1000, 5000, 10000]\n",
    "    }\n",
    "\n",
    "logistic_regression_grid = GridSearchCV(estimator=LogisticRegression(random_state = 42), param_grid=logistic_regression_params, \n",
    "                                      scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "logistic_regression_grid.fit(X_train_scaled, y_train_binary)\n",
    "best_log_model = logistic_regression_grid.best_estimator_\n",
    "best_log_params = logistic_regression_grid.best_params_\n",
    "print(\"Best Linear Regression Parameters:\", best_log_params)\n",
    "\n",
    "#Logistic regression with optimal parameters\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight = 'balanced', random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train_binary)\n",
    "y_pred_logistic = log_reg.predict(X_test_scaled)\n",
    "\n",
    "#Evaluation of logistic regression model\n",
    "\n",
    "logistic_accuracy = accuracy_score(y_test_binary, y_pred_logistic)\n",
    "logistic_precision = precision_score(y_test_binary, y_pred_logistic)\n",
    "logistic_recall = recall_score(y_test_binary, y_pred_logistic)\n",
    "logistic_f1 = f1_score(y_test_binary, y_pred_logistic)\n",
    "\n",
    "print(f'Accuracy : {logistic_accuracy}\\nPrecision : {logistic_precision}\\nRecall : {logistic_recall}\\nF1-score : {logistic_f1}')\n",
    "\n",
    "#Printing results of both models in table format\n",
    "\n",
    "performance_results = {\n",
    "    'Metric': [\n",
    "        'Root Mean Squared Error',\n",
    "        'Mean Absolute Error',\n",
    "        'R^2 Score',\n",
    "        'Accuracy',\n",
    "        'Precision',\n",
    "        'Recall',\n",
    "        'F1 Score'\n",
    "    ],\n",
    "    'Linear Regression': [\n",
    "        linear_rmse,\n",
    "        linear_mae,\n",
    "        linear_r2,\n",
    "        None,  # No value for linear regression metrics\n",
    "        None,\n",
    "        None,\n",
    "        None\n",
    "    ],\n",
    "    'Logistic Regression': [\n",
    "        None,  # No value for logistic regression metrics\n",
    "        None,\n",
    "        None,\n",
    "        logistic_accuracy,\n",
    "        logistic_precision,\n",
    "        logistic_recall,\n",
    "        logistic_f1\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(performance_results)\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
