{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0ea8ab-1907-425e-8463-d2fd0d569184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (71.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    " # Use the Magic Gamma Telescope database:\n",
    " # 1. Apply an Artificial Neural Network (ANN) classifier with:\n",
    " # • A(1-1-1) NN architecture.\n",
    " # • A(1-2-1) NN architecture\n",
    "\n",
    "!pip install numpy pandas tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b051925b-4cbe-4bf7-b946-78f1d71f3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input , layers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdc4156-e24f-44f4-aa1a-9689fe665813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>19015</td>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>19016</td>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>19017</td>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>19018</td>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>19019</td>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   fLength    fWidth   fSize   fConc  fConc1     fAsym  \\\n",
       "0               0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   \n",
       "1               1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   \n",
       "2               2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410   \n",
       "3               3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   \n",
       "4               4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   \n",
       "...           ...       ...       ...     ...     ...     ...       ...   \n",
       "19015       19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   \n",
       "19016       19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   \n",
       "19017       19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   \n",
       "19018       19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043   \n",
       "19019       19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125   \n",
       "\n",
       "        fM3Long  fM3Trans   fAlpha     fDist class  \n",
       "0       22.0110   -8.2027  40.0920   81.8828     g  \n",
       "1       23.8238   -9.9574   6.3609  205.2610     g  \n",
       "2      -64.8580  -45.2160  76.9600  256.7880     g  \n",
       "3       -6.4633   -7.1513  10.4490  116.7370     g  \n",
       "4       28.5525   21.8393   4.6480  356.4620     g  \n",
       "...         ...       ...      ...       ...   ...  \n",
       "19015   11.5245    2.8766   2.4229  106.8258     h  \n",
       "19016   13.1853   -2.9632  86.7975  247.4560     h  \n",
       "19017   41.0562   -9.4662  30.2987  256.5166     h  \n",
       "19018  -93.5224  -63.8389  84.6874  408.3166     h  \n",
       "19019 -168.4558   31.4755  52.7310  272.3174     h  \n",
       "\n",
       "[19020 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/HP/OneDrive/Desktop/ml 7th sem codes/datasets/magic.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1934d7e-151f-4b16-b441-4e3cc133b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6467 - loss: 0.6738 - val_accuracy: 0.6505 - val_loss: 0.5129\n",
      "Epoch 2/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6499 - loss: 0.4718 - val_accuracy: 0.9425 - val_loss: 0.3644\n",
      "Epoch 3/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.3343 - val_accuracy: 0.9599 - val_loss: 0.2756\n",
      "Epoch 4/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.2563 - val_accuracy: 0.9665 - val_loss: 0.2188\n",
      "Epoch 5/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.1995 - val_accuracy: 0.9740 - val_loss: 0.1778\n",
      "Epoch 6/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.1644 - val_accuracy: 0.9780 - val_loss: 0.1481\n",
      "Epoch 7/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9842 - loss: 0.1352 - val_accuracy: 0.9809 - val_loss: 0.1257\n",
      "Epoch 8/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.1137 - val_accuracy: 0.9823 - val_loss: 0.1083\n",
      "Epoch 9/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.0993 - val_accuracy: 0.9842 - val_loss: 0.0947\n",
      "Epoch 10/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0851 - val_accuracy: 0.9855 - val_loss: 0.0835\n",
      "Epoch 11/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9890 - loss: 0.0744 - val_accuracy: 0.9875 - val_loss: 0.0745\n",
      "Epoch 12/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0636 - val_accuracy: 0.9888 - val_loss: 0.0668\n",
      "Epoch 13/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0613 - val_accuracy: 0.9895 - val_loss: 0.0609\n",
      "Epoch 14/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9907 - loss: 0.0529 - val_accuracy: 0.9901 - val_loss: 0.0552\n",
      "Epoch 15/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0467 - val_accuracy: 0.9905 - val_loss: 0.0506\n",
      "Epoch 16/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0450 - val_accuracy: 0.9905 - val_loss: 0.0470\n",
      "Epoch 17/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0392 - val_accuracy: 0.9915 - val_loss: 0.0436\n",
      "Epoch 18/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0370 - val_accuracy: 0.9918 - val_loss: 0.0405\n",
      "Epoch 19/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0345 - val_accuracy: 0.9921 - val_loss: 0.0380\n",
      "Epoch 20/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0319 - val_accuracy: 0.9921 - val_loss: 0.0356\n",
      "Epoch 21/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0286 - val_accuracy: 0.9924 - val_loss: 0.0338\n",
      "Epoch 22/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0288 - val_accuracy: 0.9921 - val_loss: 0.0320\n",
      "Epoch 23/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0267 - val_accuracy: 0.9931 - val_loss: 0.0305\n",
      "Epoch 24/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0246 - val_accuracy: 0.9931 - val_loss: 0.0292\n",
      "Epoch 25/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0234 - val_accuracy: 0.9934 - val_loss: 0.0278\n",
      "Epoch 26/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0216 - val_accuracy: 0.9938 - val_loss: 0.0267\n",
      "Epoch 27/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0205 - val_accuracy: 0.9944 - val_loss: 0.0255\n",
      "Epoch 28/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0217 - val_accuracy: 0.9947 - val_loss: 0.0249\n",
      "Epoch 29/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0186 - val_accuracy: 0.9944 - val_loss: 0.0240\n",
      "Epoch 30/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0187 - val_accuracy: 0.9954 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0178 - val_accuracy: 0.9954 - val_loss: 0.0224\n",
      "Epoch 32/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0156 - val_accuracy: 0.9957 - val_loss: 0.0215\n",
      "Epoch 33/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0161 - val_accuracy: 0.9961 - val_loss: 0.0209\n",
      "Epoch 34/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0162 - val_accuracy: 0.9954 - val_loss: 0.0204\n",
      "Epoch 35/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0169 - val_accuracy: 0.9957 - val_loss: 0.0199\n",
      "Epoch 36/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0154 - val_accuracy: 0.9957 - val_loss: 0.0194\n",
      "Epoch 37/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0149 - val_accuracy: 0.9961 - val_loss: 0.0189\n",
      "Epoch 38/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0150 - val_accuracy: 0.9957 - val_loss: 0.0185\n",
      "Epoch 39/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0141 - val_accuracy: 0.9957 - val_loss: 0.0183\n",
      "Epoch 40/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0141 - val_accuracy: 0.9964 - val_loss: 0.0175\n",
      "Epoch 41/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0134 - val_accuracy: 0.9964 - val_loss: 0.0169\n",
      "Epoch 42/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0131 - val_accuracy: 0.9964 - val_loss: 0.0169\n",
      "Epoch 43/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0126 - val_accuracy: 0.9961 - val_loss: 0.0165\n",
      "Epoch 44/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0126 - val_accuracy: 0.9964 - val_loss: 0.0162\n",
      "Epoch 45/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0128 - val_accuracy: 0.9957 - val_loss: 0.0162\n",
      "Epoch 46/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0121 - val_accuracy: 0.9967 - val_loss: 0.0156\n",
      "Epoch 47/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9964 - val_loss: 0.0153\n",
      "Epoch 48/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0107 - val_accuracy: 0.9967 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0116 - val_accuracy: 0.9964 - val_loss: 0.0154\n",
      "Epoch 50/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0109 - val_accuracy: 0.9961 - val_loss: 0.0148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x228040c0c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANN Classifier: 1-1-1\n",
    "X = data.drop('class', axis=1).values  # Features\n",
    "y = data[\"class\"].apply(lambda x: 1 if x == \"g\" else 0)  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#create a model model_a\n",
    "model_a = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(1, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "model_a.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_a.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5784b0-0ac7-4357-b9e1-5fc053d6ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9963 - loss: 0.0141\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n",
      "Model A - Loss: 0.014875608496367931, Accuracy: 0.9955310225486755\n",
      "Model A - Precision: 0.9959399106780349, Recall: 0.9971544715447155, F1 Score: 0.9965468210440788\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "loss_A, accuracy_A = model_a.evaluate(X_test, y_test)\n",
    "\n",
    "y_pred_A = (model_a.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "precision_A = precision_score(y_test, y_pred_A)\n",
    "recall_A = recall_score(y_test, y_pred_A)\n",
    "f1_A = f1_score(y_test, y_pred_A)\n",
    "\n",
    "print(f\"Model A - Loss: {loss_A}, Accuracy: {accuracy_A}\")\n",
    "print(f\"Model A - Precision: {precision_A}, Recall: {recall_A}, F1 Score: {f1_A}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0312a856-d3b3-4f35-b09f-c5add84738d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.5653 - val_accuracy: 0.9507 - val_loss: 0.1900\n",
      "Epoch 2/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9761 - loss: 0.1192 - val_accuracy: 0.9819 - val_loss: 0.0691\n",
      "Epoch 3/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9865 - loss: 0.0480 - val_accuracy: 0.9832 - val_loss: 0.0511\n",
      "Epoch 4/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0315 - val_accuracy: 0.9829 - val_loss: 0.0459\n",
      "Epoch 5/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0239 - val_accuracy: 0.9882 - val_loss: 0.0371\n",
      "Epoch 6/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.9898 - val_loss: 0.0348\n",
      "Epoch 7/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0183 - val_accuracy: 0.9892 - val_loss: 0.0308\n",
      "Epoch 8/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0163 - val_accuracy: 0.9901 - val_loss: 0.0293\n",
      "Epoch 9/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0136 - val_accuracy: 0.9934 - val_loss: 0.0276\n",
      "Epoch 10/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0141 - val_accuracy: 0.9928 - val_loss: 0.0269\n",
      "Epoch 11/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0120 - val_accuracy: 0.9911 - val_loss: 0.0245\n",
      "Epoch 12/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0129 - val_accuracy: 0.9941 - val_loss: 0.0241\n",
      "Epoch 13/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0106 - val_accuracy: 0.9924 - val_loss: 0.0238\n",
      "Epoch 14/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0103 - val_accuracy: 0.9928 - val_loss: 0.0215\n",
      "Epoch 15/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.9931 - val_loss: 0.0192\n",
      "Epoch 16/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0078 - val_accuracy: 0.9934 - val_loss: 0.0190\n",
      "Epoch 17/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0079 - val_accuracy: 0.9941 - val_loss: 0.0180\n",
      "Epoch 18/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0078 - val_accuracy: 0.9938 - val_loss: 0.0185\n",
      "Epoch 19/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9941 - val_loss: 0.0176\n",
      "Epoch 20/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0074 - val_accuracy: 0.9954 - val_loss: 0.0181\n",
      "Epoch 21/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.9954 - val_loss: 0.0199\n",
      "Epoch 22/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9941 - val_loss: 0.0158\n",
      "Epoch 23/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.9947 - val_loss: 0.0157\n",
      "Epoch 24/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.9954 - val_loss: 0.0166\n",
      "Epoch 25/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.9957 - val_loss: 0.0172\n",
      "Epoch 26/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9957 - val_loss: 0.0165\n",
      "Epoch 27/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 0.9951 - val_loss: 0.0154\n",
      "Epoch 28/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9957 - val_loss: 0.0144\n",
      "Epoch 29/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9967 - val_loss: 0.0160\n",
      "Epoch 30/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9964 - val_loss: 0.0147\n",
      "Epoch 31/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.9957 - val_loss: 0.0141\n",
      "Epoch 32/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9957 - val_loss: 0.0153\n",
      "Epoch 33/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9957 - val_loss: 0.0149\n",
      "Epoch 34/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9947 - val_loss: 0.0161\n",
      "Epoch 35/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9951 - val_loss: 0.0143\n",
      "Epoch 36/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9967 - val_loss: 0.0161\n",
      "Epoch 37/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9967 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9967 - val_loss: 0.0134\n",
      "Epoch 39/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9947 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9957 - val_loss: 0.0137\n",
      "Epoch 41/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.9951 - val_loss: 0.0136\n",
      "Epoch 42/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9964 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9967 - val_loss: 0.0153\n",
      "Epoch 44/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9961 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.9967 - val_loss: 0.0147\n",
      "Epoch 46/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.9970 - val_loss: 0.0146\n",
      "Epoch 47/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9970 - val_loss: 0.0151\n",
      "Epoch 48/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.9964 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 0.9951 - val_loss: 0.0163\n",
      "Epoch 50/50\n",
      "\u001b[1m381/381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9970 - val_loss: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x228016fe5d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANN 1-1-1-1\n",
    "#create a model model_b\n",
    "model_b = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(10, activation='relu'),# Hidden layer\n",
    "    layers.Dense(5,activation='relu'),#Hidden layer\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_b.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c234c27-5538-4cff-b4fc-c43ab7cdad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9975 - loss: 0.0074\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "Model B - Loss: 0.008972098119556904, Accuracy: 0.996582567691803\n",
      "Model B - Precision: 0.9991840065279478, Recall: 0.9955284552845528, F1 Score: 0.9973528812869069\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss_B, accuracy_B = model_b.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "y_pred_B = (model_b.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "precision_B = precision_score(y_test, y_pred_B)\n",
    "recall_B = recall_score(y_test, y_pred_B)\n",
    "f1_B = f1_score(y_test, y_pred_B)\n",
    "\n",
    "print(f\"Model B - Loss: {loss_B}, Accuracy: {accuracy_B}\")\n",
    "print(f\"Model B - Precision: {precision_B}, Recall: {recall_B}, F1 Score: {f1_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247dccb7-af10-4be3-9d1e-5be86dc58c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Accuracy  Precision    Recall  F1 Score\n",
      "0    Model A (1-1-1)  0.995531   0.995940  0.997154  0.996547\n",
      "1  Model B (1-1-1-1)  0.996583   0.999184  0.995528  0.997353\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Model A (1-1-1)\", \"Model B (1-1-1-1)\"],\n",
    "    \"Accuracy\": [accuracy_A, accuracy_B],\n",
    "    \"Precision\": [precision_A, precision_B],\n",
    "    \"Recall\": [recall_A, recall_B],\n",
    "    \"F1 Score\": [f1_A, f1_B]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674a6d0-fd06-4f51-af37-6f43c569328f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
